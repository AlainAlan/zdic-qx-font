{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 搗包\n",
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.parse\n",
    "import time\n",
    "import opencc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 挑選字符"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "字頻 = []\n",
    "with open('characters_traditional_frequencies.csv', 'r',encoding='utf8') as f: # 您瞧這名字多長\n",
    "    lines = f.readlines()\n",
    "    print(len(lines))\n",
    "    for line in lines[0:6000]:\n",
    "        字頻.append(line.split(',')[0].strip())\n",
    "print(len(字頻))\n",
    "字頻[0:5]\n",
    "# 第一個是什麽鬼\n",
    "字頻.pop(0)\n",
    "字頻[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 爬取字符"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.212 Safari/537.36'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 字頻[799]\n",
    "# # 確認某個位置是不是某個字\n",
    "# # double-check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "字頻.index('杵')\n",
    "# # 這個用來檢查現在爬蟲到第幾個字了\n",
    "# # 在爬蟲過程中我是在另外一個ipynb裏檢查的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for zi in 字頻[79:100]:\n",
    "for zi in 字頻[5985:6001]:\n",
    "#     print(zi)\n",
    "    zi_parse = urllib.parse.quote(zi)\n",
    "    url = 'https://www.zdic.net/zd/zx/qx/' + zi_parse\n",
    "    r = requests.get(url,headers=headers)\n",
    "    text = r.text\n",
    "    soup = BeautifulSoup(text, 'html.parser')\n",
    "    try:\n",
    "        jw = soup.find(name='div',attrs={\"class\": \"zy1\"})\n",
    "        img_list = jw.find_all(name='img')\n",
    "        \n",
    "        headers['Referer'] = url\n",
    "\n",
    "        for img in img_list[0:1]:\n",
    "            # 暫時只要第一個\n",
    "            src = 'https:'+ img.get('data-original')\n",
    "            res = requests.get(url=src,headers=headers)\n",
    "            filename = zi+'.svg'\n",
    "            with open(filename,'wb') as f:\n",
    "                f.write(res.content)        \n",
    "    except:\n",
    "        print(str(字頻.index(zi)) + zi + '沒有秦系文字')\n",
    "        time.sleep(10)\n",
    "        continue\n",
    "    time.sleep(11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 查漏補缺"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GB2312全部單字\n",
    "GB2312 = []\n",
    "with open('GB2312.txt','r',encoding='utf8') as gb:\n",
    "    lines = gb.readlines()\n",
    "    for line in lines:\n",
    "        for word in line.strip():\n",
    "            GB2312.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = opencc.OpenCC('t2s.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converter = opencc.OpenCC('t2s.json')\n",
    "# converter.convert('汉字')  # 漢字\n",
    "zipin_s = []\n",
    "for char in 字頻:\n",
    "    char_s = converter.convert(char)\n",
    "    zipin_s.append(char_s)\n",
    "zipin_lack = list(set(GB2312).difference(set(zipin_s)))\n",
    "# 字頻中所有字符簡化，求差，備用（需要補充爬取，雖然幾乎不會有字）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(len(zipin_lack))\n",
    "print(zipin_lack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2t_converter = opencc.OpenCC('s2t.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s2t_converter = opencc.OpenCC('s2t.json')\n",
    "\n",
    "for zi_s in zipin_lack:\n",
    "    zi = s2t_converter.convert(zi_s)\n",
    "    # 先转成繁体字，按照繁体字比较靠谱些\n",
    "    # 反正这些是之前字频里面没有的\n",
    "    # 早知道就直接用GB2312爬了\n",
    "    # 最初只是想搞几个常用字而已\n",
    "    # 没想到后来心变大了\n",
    "    zi_parse = urllib.parse.quote(zi)\n",
    "    url = 'https://www.zdic.net/zd/zx/qx/' + zi_parse\n",
    "    r = requests.get(url,headers=headers)\n",
    "    text = r.text\n",
    "    soup = BeautifulSoup(text, 'html.parser')\n",
    "    try:\n",
    "        jw = soup.find(name='div',attrs={\"class\": \"zy1\"})\n",
    "        img_list = jw.find_all(name='img')\n",
    "        \n",
    "        headers['Referer'] = url\n",
    "        # 更新请求头，否则403\n",
    "        \n",
    "        for img in img_list[0:1]:\n",
    "            # 暫時只要第一個\n",
    "            # 其实以后可以做一个alternative字体\n",
    "            # 很多英文字体都有防止重复出现的替换字型\n",
    "            \n",
    "            src = 'https:'+ img.get('data-original')\n",
    "            res = requests.get(url=src,headers=headers)\n",
    "            filename = zi+'.svg'\n",
    "            with open(filename,'wb') as f:\n",
    "                f.write(res.content)        \n",
    "    except:\n",
    "        print(str(zipin_lack.index(zi_s)) + zi + '沒有秦系') # 手動查索引太累了\n",
    "        time.sleep(15)\n",
    "        continue\n",
    "    time.sleep(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 鏡像給簡體字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "一簡對一繁之簡體字 = []\n",
    "一簡對多繁之簡體字 = []\n",
    "with open('STCharacters.txt','r',encoding='utf8') as st:\n",
    "    lines = st.readlines()\n",
    "    for line in lines:\n",
    "        a_dict = line.split('\\t')\n",
    "        k_s = a_dict[0]\n",
    "        v_t = a_dict[1].split(' ')\n",
    "        if len(v_t) == 1:\n",
    "            一簡對一繁之簡體字.append(k_s)\n",
    "        else:\n",
    "            一簡對多繁之簡體字.append(k_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2t_dict = {}\n",
    "with open('STCharacters.txt','r',encoding='utf8') as st:\n",
    "    lines = st.readlines()\n",
    "    for line in lines:\n",
    "        a_dict = line.split('\\t')\n",
    "        s = a_dict[0]\n",
    "        t = a_dict[1].strip()\n",
    "        s2t_dict[s] = t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = []\n",
    "for home, dirs, files in os.walk('qx_watermark_removed/'): \n",
    "     for file in files:\n",
    "        L.append(os.path.join(home, file))\n",
    "# len(L)\n",
    "list_of_svg_char = []\n",
    "for l in L:\n",
    "    char = l.split('.')[0][-1]\n",
    "    list_of_svg_char.append(char)\n",
    "# a = 0\n",
    "will_be_mirrored_s_char = []\n",
    "for s in list_of_svg_char:\n",
    "    ss = converter.convert(s)\n",
    "    if ss not in 一簡對多繁之簡體字 and ss not in list_of_svg_char:\n",
    "#     if s2t_dict[s] in list_of_svg_char:\n",
    "#         a += 1\n",
    "#         if s not in list_of_svg_char:\n",
    "        # 要保證這個簡體字型不僅有對應繁體字，\n",
    "        # 還要保證它本身不在已有的svg之内\n",
    "        will_be_mirrored_s_char.append(ss)\n",
    "            # 然後才鏡像之\n",
    "# print(a)\n",
    "len(will_be_mirrored_s_char)\n",
    "# 之後在js裏面鏡像，不複製本地文件\n",
    "# 在最後輸出之前要先去水印的\n",
    "# # 具體：\n",
    "# for s_char in will_be_mirrored_s_char:\n",
    "#     jscode = \"font.setSvg('\" + s_char + \"', fs.readFileSync('去水印/\" + s2t_dict[s] + \".svg').toString())\\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 去掉水印"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將爬取的全部文件放到“去水印”文件夾中\n",
    "# https://blog.csdn.net/qq_37174526/article/details/89489212\n",
    "from xml.dom.minidom import parse\n",
    "\n",
    "def 去水印(filename):\n",
    "    svg = parse(filename)\n",
    "    rootNode = svg.documentElement\n",
    "#     print(rootNode.nodeName)\n",
    "    gs = rootNode.getElementsByTagName(\"g\")\n",
    "    for g in gs:\n",
    "        if g.hasAttribute('fill'):\n",
    "            color = g.getAttribute('fill')\n",
    "            if color[-2:] in ['fa','fb','fc']:\n",
    "#                 print(color)\n",
    "                rootNode.removeChild(g)\n",
    "\n",
    "    path = rootNode.getElementsByTagName(\"path\")\n",
    "    for p in path:\n",
    "        if p.hasAttribute('fill'):\n",
    "            color = p.getAttribute('fill')\n",
    "    #         print(color[-2:])\n",
    "            if color[-2:] in ['fa','fb','fc']:\n",
    "#                 print(color)\n",
    "                rootNode.removeChild(p)\n",
    "    # print(rootNode.toxml())\n",
    "    with open(filename,'w') as f:\n",
    "        f.write(rootNode.toxml())\n",
    "        \n",
    "## 注釋：\n",
    "# 水印的位置和中英文是隨機的，但顔色是近似的，故而利用fill的顔色來判斷是否是水印\n",
    "# 在瀏覽器中不可見，但是在轉換爲字體之後，會顯現出顔色（單色）\n",
    "# 所以利用xml的優勢去除水印"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 獲取所有文件名\n",
    "# 懶得寫代碼，沒有確認文件擴展名，\n",
    "# 所以需要手動刪除測試中生成的其他文件\n",
    "# L = []\n",
    "# for home, dirs, files in os.walk('去水印'): \n",
    "#      for file in files:\n",
    "#         L.append(os.path.join(home, file))\n",
    "# 這一步已經挪到了上面\n",
    "\n",
    "\n",
    "len(L)\n",
    "# https://www.cnblogs.com/frisk/p/11567175.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in L:\n",
    "    去水印(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 輸出Node.js代碼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('create_qx_font.js','w',encoding='utf8') as f:\n",
    "    f.write('''\n",
    "var fontCarrier = require('font-carrier')\\n\n",
    "var font = fontCarrier.create()\\n\n",
    "var fs = require('fs')\\n\n",
    "''')\n",
    "    # https://stackoverflow.com/questions/29835440/meteor-referenceerror-fs-is-not-defined\n",
    "    for l in L:\n",
    "        char = l.split('.')[0][-1]\n",
    "        jscode = \"font.setSvg('\" + char + \"', fs.readFileSync('\" + l.replace('\\\\','/') + \"').toString())\\n\"\n",
    "        f.write(jscode)\n",
    "    for s_char in will_be_mirrored_s_char:\n",
    "        t_char = s2t_converter.convert(s_char)\n",
    "        if t_char in list_of_svg_char:\n",
    "            jscode = \"font.setSvg('\" + s_char + \"', fs.readFileSync('qx_watermark_removed//\" + t_char + \".svg').toString())\\n\"\n",
    "            f.write(jscode)\n",
    "\n",
    "    f.write('''\n",
    "font.output({\n",
    "    path: './iconfont'\n",
    "})\n",
    "    ''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 後續操作\n",
    "打開PowerShell, 安裝font-carrier后\n",
    "輸入\n",
    "```\n",
    "node create_font.js\n",
    "```\n",
    "即可獲得輸出的多種格式的字體文件"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
